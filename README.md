# ðŸ§® Principal Component Analysis (PCA) â€” Dimensionality Reduction & Clustering

This project demonstrates how **Principal Component Analysis (PCA)** can be used to reduce dataset dimensionality while retaining most of the variance.  
We also compare **K-Means clustering performance** before and after PCA using the **Wine dataset**.

---

## ðŸ§© Project Overview
- Load and preprocess the dataset  
- Visualize distributions and correlations  
- Perform PCA for dimensionality reduction  
- Evaluate explained variance  
- Apply K-Means clustering on:
  1. Original data  
  2. PCA-transformed data  
- Compare performance using **Silhouette Score** and **Daviesâ€“Bouldin Index**

---

## ðŸ“Š Technologies Used
- Python  
- Pandas, NumPy, Matplotlib, Seaborn  
- Scikit-learn (PCA, K-Means, Metrics)  

---

## ðŸ§  Key Highlights
âœ” Achieved 95% variance retention with fewer components  
âœ” Improved clustering efficiency after dimensionality reduction  
âœ” Visualized clean cluster separation in PCA-reduced space  
âœ” Demonstrated trade-offs between variance retention and interpretability  
